{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "\n",
    "\n",
    "from gpytorch.kernels import RBFKernel\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
    "\n",
    "from utils.HelperFunctions import *\n",
    "from utils.Models import *\n",
    "from utils.Kernels import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up logger. Training MOGP models in this research takes quite some time, especially if you are doing massive scale grid search or cross validation. The logger here is to assure even when training unexpectedly terminated with anomaly, records are still kept for later query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamHandler added\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('The_Logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler('result.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "error = logging.getLogger('error')\n",
    "error.setLevel(logging.DEBUG)\n",
    "error_fh=logging.FileHandler('error.log')\n",
    "error_fh.setLevel(logging.DEBUG)\n",
    "error_ch=logging.StreamHandler()\n",
    "error_fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "\n",
    "if not any(isinstance(handler, logging.StreamHandler) for handler in logger.handlers):\n",
    "    error.addHandler(error_fh)\n",
    "    error.addHandler(error_ch)\n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(ch)\n",
    "    print(\"StreamHandler added\")\n",
    "else:\n",
    "    print(\"StreamHandler already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274, 1084)\n",
      "(274, 10)\n",
      "(274, 1)\n",
      "Shape of X_train:torch.Size([246, 1084])\n",
      "Shape of X_D_train(domain information of X_train):torch.Size([246, 1084])\n",
      "Shape of y_train:torch.Size([246, 10])\n"
     ]
    }
   ],
   "source": [
    "X_path,y_path,X_domain_path=get_dataset_path(\"FULL_SHOTS\")\n",
    "(X_train_tensor,X_D_train_tensor,y_train_tensor),(X_test_tensor,X_D_test_tensor,y_test_tensor)=load_dataset(X_path,y_path,X_domain_path=X_domain_path)\n",
    "\n",
    "print(f\"Shape of X_train:{X_train_tensor.shape}\")\n",
    "print(f\"Shape of X_D_train(domain information of X_train):{X_train_tensor.shape}\")\n",
    "print(f\"Shape of y_train:{y_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating & configuring some global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMS_DOMAIN: 30.0\n",
      "torch.Size([246, 1085])\n",
      "torch.Size([28, 1085])\n"
     ]
    }
   ],
   "source": [
    "Global=config()\n",
    "\n",
    "\n",
    "Global.NUM_CONC=y_train_tensor.shape[1]\n",
    "\n",
    "Global.NUM_FEAT=X_train_tensor.shape[1]\n",
    "Global.NUM_DOMAIN_FEAT=X_D_train_tensor.shape[1]\n",
    "NUMS_DOMAIN, max_indices_row = torch.max(X_D_train_tensor, dim=0)\n",
    "NUMS_DOMAIN.add_(1)\n",
    "\n",
    "\n",
    "print(f'NUMS_DOMAIN: {NUMS_DOMAIN.item()}')\n",
    "Global.NUMS_DOMAIN=NUMS_DOMAIN.long()\n",
    "X_train_tensor = torch.cat((X_D_train_tensor, X_train_tensor), dim=1)\n",
    "X_test_tensor = torch.cat((X_D_test_tensor, X_test_tensor), dim=1)\n",
    "print(X_train_tensor.shape)\n",
    "print(X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage of cross validation unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Global.lr=0.1\n",
    "Global.gamma=0.5\n",
    "Global.STEP_SIZE=50\n",
    "Global.NUMS_DOMAIN_FEATURE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= [\n",
    "    # [MultitaskGP, RBFKernel, 0.18, 55, 0.8],\n",
    "    # [Linear_Model_Of_Corregionalization, RBFKernel, 0.1, 60, 0.8],\n",
    "    # [MultitaskGP, K_MS, 0.18, 55, 0.65],\n",
    "    [Linear_Model_Of_Corregionalization, K_Alpha_Beta,0.69, 33, 0.2],\n",
    "    # [MultitaskGP, K_MS_with_Feat_Scaling, 0.18, 55,0.65],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat((X_train_tensor, X_test_tensor), dim=0)\n",
    "y = torch.cat((y_train_tensor, y_test_tensor), dim=0)\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "fold_results = {} # to store result of each folds\n",
    "m=[]\n",
    "nlls=[]\n",
    "for each_param in params:\n",
    "        Global.lr=each_param[2]\n",
    "        Global.STEP_SIZE=each_param[3]\n",
    "        Global.gamma=each_param[4]\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "            logger.info('--------------------------------')\n",
    "            logger.info(f'FOLD {fold+1}')\n",
    "\n",
    "            \n",
    "            # creating training and validation sets\n",
    "            train_subset = Subset(dataset, train_idx)\n",
    "            val_subset = Subset(dataset, val_idx)\n",
    "            \n",
    "            # creating dataloaders\n",
    "            train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "            val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "            X_train_tensor,y_train_tensor=dataloader2tensor(train_loader)\n",
    "            X_test_tensor,y_test_tensor=dataloader2tensor(val_loader)\n",
    "            try:\n",
    "                md,n=run_test(X_train_tensor,y_train_tensor,X_test_tensor,y_test_tensor,model=each_param[0],kernel=each_param[1],config=Global,logger=logger)\n",
    "                m.append(md)\n",
    "                nlls.append(n)\n",
    "            except Exception as e:\n",
    "                error.error(f\"Model:{str(each_param[0])}; Kernel:{str(each_param[1])}; lr:{str(Global.lr)};STEP_SIZE:{str(Global.STEP_SIZE)}; {e}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage of grid search unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'models':[Linear_Model_Of_Corregionalization],\n",
    "    'kernels': [RBFKernel],\n",
    "    'lrs': [0.69 ],\n",
    "    'gammas':[0.5],\n",
    "    'STEP_SIZEs':[33]\n",
    "}\n",
    "\n",
    "grid_search(X_train_tensor,y_train_tensor,X_test_tensor,y_test_tensor,param_grid,Global)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
